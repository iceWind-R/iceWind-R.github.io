<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <meta name="baidu-site-verification" content="OIvRHPtnvC">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-loading-bar.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"icewind-r.github.io","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本篇开始学习大数据Hadoop技术中的核心之一 —— HDFS。">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据_03(HDFS基础)">
<meta property="og:url" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/index.html">
<meta property="og:site_name" content="Thorine">
<meta property="og:description" content="本篇开始学习大数据Hadoop技术中的核心之一 —— HDFS。">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/1.gif">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/2.png">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/3.png">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/4.png">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/5.png">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/6.png">
<meta property="og:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/7.png">
<meta property="article:published_time" content="2020-08-09T01:45:01.000Z">
<meta property="article:modified_time" content="2020-09-14T02:38:12.938Z">
<meta property="article:author" content="大雪初晴丶">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/1.gif">

<link rel="canonical" href="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>大数据_03(HDFS基础) | Thorine</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a170e4a05c3a0ce3f8d5a6919dae5d5e";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Thorine" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    	<!-- 自己的Github地址 -->

<a href="https://github.com/iceWind-R" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Thorine</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">凡是过往，皆为序章</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://icewind-r.github.io/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang01.jpg">
      <meta itemprop="name" content="大雪初晴丶">
      <meta itemprop="description" content="一个热爱编程的大二小白">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thorine">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大数据_03(HDFS基础)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">



                
                

                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-09 09:45:01" itemprop="dateCreated datePublished" datetime="2020-08-09T09:45:01+08:00">2020-08-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-14 10:38:12" itemprop="dateModified" datetime="2020-09-14T10:38:12+08:00">2020-09-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
            </span>

          
            <span id="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/" class="post-meta-item leancloud_visitors" data-flag-title="大数据_03(HDFS基础)" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>



        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本篇开始学习大数据Hadoop技术中的<strong>核心</strong>之一 —— HDFS。</p>
<a id="more"></a>

<hr>
<h1 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>HDFS （Hadoop Distributed File System）是Hadoop抽象文件系统的一种实现。Hadoop抽象文件系统可以与本地系统、Amazon S3等集成，甚至可以通过Web协议（webhsfs）来操作。HDFS的文件分布在集群机器上，同时提供副本进行容错及可靠性保证。例如客户端写入读取文件的直接操作都是分布在集群各个机器上的，没有单点性能压力。</p>
<h2 id="HDFS设计原则"><a href="#HDFS设计原则" class="headerlink" title="HDFS设计原则"></a>HDFS设计原则</h2><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><ul>
<li><strong>存储非常大的文件</strong>：这里非常大指的是几百M、G、或者TB级别。实际应用中已有很多集群存储的数据达到PB级别。根据Hadoop官网，Yahoo！的Hadoop集群约有10万颗CPU，运行在4万个机器节点上。更多世界上的Hadoop集群使用情况，参考<a href="https://wiki.apache.org/hadoop/PoweredBy" target="_blank" rel="noopener">Hadoop官网</a>.</li>
<li><strong>采用流式的数据访问方式</strong>: HDFS基于这样的一个假设：最有效的数据处理模式是一次写入、多次读取数据集经常从数据源生成或者拷贝一次，然后在其上做很多分析工作<br>分析工作经常读取其中的大部分数据，即使不是全部。 因此读取整个数据集所需时间比读取第一条记录的延时更重要。</li>
<li><strong>运行于商业硬件上</strong>: Hadoop不需要特别贵的、reliable的（可靠的）机器，可运行于普通商用机器（可以从多家供应商采购） ，商用机器不代表低端机器。在集群中（尤其是大的集群），节点失败率是比较高的HDFS的目标是确保集群在节点失败的时候不会让用户感觉到明显的中断。</li>
</ul>
<h3 id="HDFS不适合的应用类型"><a href="#HDFS不适合的应用类型" class="headerlink" title="HDFS不适合的应用类型"></a>HDFS不适合的应用类型</h3><p>有些场景不适合使用HDFS来存储数据。下面列举几个：</p>
<p>1） <strong>低延时的数据访问</strong><br>对延时要求在毫秒级别的应用，不适合采用HDFS。HDFS是为高吞吐数据传输设计的,因此可能牺牲延时HBase更适合低延时的数据访问。</p>
<p>2）<strong>大量小文件</strong><br>文件的元数据（如目录结构，文件block的节点列表，block-node mapping）保存在NameNode的内存中， 整个文件系统的文件数量会受限于NameNode的内存大小。<br>经验而言，一个文件/目录/文件块一般占有150字节的元数据内存空间。如果有100万个文件，每个文件占用1个文件块，则需要大约300M的内存。因此十亿级别的文件数量在现有商用机器上难以支持。</p>
<p>3）<strong>多方读写，需要任意的文件修改</strong><br>HDFS采用追加（append-only）的方式写入数据。不支持文件任意offset的修改。不支持多个写入器（writer）。</p>
<h1 id="HDFS的架构"><a href="#HDFS的架构" class="headerlink" title="HDFS的架构"></a>HDFS的架构</h1><p>HDFS是一个 主 / 从（Master / Slave）体系结构。</p>
<p>HDFS由四部分组成，HDFS Client、NameNode，DataNode 和 Secondary NameNode。</p>
<h2 id="1、Client：就是客户端"><a href="#1、Client：就是客户端" class="headerlink" title="1、Client：就是客户端"></a>1、Client：就是客户端</h2><ul>
<li>文件切片。文件上传到HDFS时，Client将文件切分成一个一个的 Block进行存储。</li>
<li>与NameNode交互，获取文件的位置信息。</li>
<li>与DataNode交互，读取或者写入数据。</li>
<li>Client提供一些命令来管理和访问HDFS，比如启动或关闭HDFS。</li>
</ul>
<h2 id="2、NameNode：就是Master，是一个主管、管理者"><a href="#2、NameNode：就是Master，是一个主管、管理者" class="headerlink" title="2、NameNode：就是Master，是一个主管、管理者"></a>2、NameNode：就是Master，是一个主管、管理者</h2><ul>
<li>管理HDFS的名称空间 和 文件数据块（Block）的映射信息，整个HDFS可存储的文件数受限于NameNode的内存大小。在内存中加载文件系统中每个文件和每个数据块的引用关系（文件、Block 和 DataNode之间的映射关系），数据会定期保存在本地磁盘（fsImage 镜像 文件 和 edits 日志 文件）。</li>
<li>配置副本策略：文件数据块到底存放到那些DataNode上，是由NameNode决定的，它根据全局情况做出放置副本的决定。</li>
<li>处理客户端读写请求。数据流不经过NameNode，会询问它与那个DataNode联系</li>
<li>NameNode心跳机制：DataNode定期发给NameNode一个个包，称为心跳机制。若NameNode没有收到，则认为相应的DataNode已经宕机，这时候NN准备要把DN上的数据块进行重新复制</li>
</ul>
<h2 id="3、DataNode-：就是Slave。"><a href="#3、DataNode-：就是Slave。" class="headerlink" title="3、DataNode ：就是Slave。"></a>3、DataNode ：就是Slave。</h2><p>Name Node下达命令，DataNode执行</p>
<ul>
<li>存储实际的数据块</li>
<li>执行数据的 读/写 操作</li>
<li>周期性的向NameNode汇报心跳信息、数据块信息 和 缓存数据块信息</li>
</ul>
<h2 id="4、Secondary-NameNode"><a href="#4、Secondary-NameNode" class="headerlink" title="4、Secondary NameNode"></a>4、Secondary NameNode</h2><p>并非NameNode的热备。当NameNode挂掉时，它并不能马上替换NameNode并提供服务。</p>
<ul>
<li>辅助NameNode，分担其工作量。</li>
<li>定期合并fsimage 和 fsedits，并推送给NameNode。</li>
</ul>
<img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/1.gif" class>

<h1 id="HDFS的副本机制和机架感知"><a href="#HDFS的副本机制和机架感知" class="headerlink" title="HDFS的副本机制和机架感知"></a>HDFS的副本机制和机架感知</h1><h2 id="HDFS文件副本机制"><a href="#HDFS文件副本机制" class="headerlink" title="HDFS文件副本机制"></a>HDFS文件副本机制</h2><p>所有文件都是以 Block 块的方式存放在HDFS文件系统中，作用如下：</p>
<ol>
<li>一个文件可能大于集群中任意一个磁盘，引入块机制分布存储可以解决该问题。</li>
<li>使用块作为文件存储的逻辑单位可以简化存储子系统</li>
<li>块非常适用于数据备份进而提供数据容错能力</li>
</ol>
<p>Block的块大小可以通过hdfs-site.xml当中的配置文件进行指定，默认128M。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>块大小 以字节为单位<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="机架感知"><a href="#机架感知" class="headerlink" title="机架感知"></a>机架感知</h2><p>HDFS分布式文件系统的内部有一个副本存放策略：以默认的副本数 = 3 为例：</p>
<p>1、第一个副本块存本机</p>
<p>2、第二个副本块跟本机同机架内的其他服务器结点</p>
<p>3、第三个副本块存不同机架的一个服务器结点上</p>
<h1 id="HDFS的命令行使用"><a href="#HDFS的命令行使用" class="headerlink" title="HDFS的命令行使用"></a>HDFS的命令行使用</h1><p>hdfs命令是操作HDFS文件系统上的资源，只要打开了HDFS服务，就可使用命令行操作，与当前所在的Linux目录无关。</p>
<p><code>ls</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式：hdfs dfs -ls URI</span><br><span class="line">作用：类似于Linux的ls命令，显示文件列表</span><br><span class="line"></span><br><span class="line">hdfs dfs -ls /</span><br></pre></td></tr></table></figure>

<p><code>ls -R</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -ls -R URI</span><br><span class="line">作用 ： 在整个目录下递归执行ls，与UNIX中的ls-R类似</span><br><span class="line"></span><br><span class="line">hdfs dfs -ls -R /</span><br></pre></td></tr></table></figure>

<p><code>mkdir</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs [-p] -mkdir &lt;paths&gt;</span><br><span class="line">作用 ： 以&lt;paths&gt;中的URI作为参数，创建目录。使用-p参数可以递归创建目录</span><br><span class="line"></span><br><span class="line">hdfs dfs -mkdir /TestDir1</span><br><span class="line">hdfs dfs -mkdir -p /TestDir2/test</span><br></pre></td></tr></table></figure>

<p>在hdfs文件系统中，可以通过50070端口查看文件系统的结构。</p>
<img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/2.png" class>

<p><code>put</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -put &lt;localsrc&gt; ... &lt;dst&gt;</span><br><span class="line">作用 ： 将单个的源文件src或者多个源文件srcs从本地文件系统拷贝到目标文件系统中（&lt;dst&gt;对应的目录）。也可以从标准输入中读取输入，写入目标文件系统中。</span><br><span class="line"></span><br><span class="line">hdfs dfs -put  /home/a.txt  /TestDir1</span><br></pre></td></tr></table></figure>

<p><code>moveFromLocal</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;</span><br><span class="line">作用 ： 和put命令类似，但put相当于复制，此命令相当于将本地文件 剪切 到hdfs中。</span><br><span class="line"></span><br><span class="line">hdfs dfs -moveFromLocal a.txt /TestDir2</span><br></pre></td></tr></table></figure>

<p><code>get</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -get [-ignorecrc] [-crc] &lt;src&gt; &lt;localhost&gt;</span><br><span class="line">作用 ： 将文件拷贝到本地文件系统，CRC 校验失败的文件通过-ignorecrc选项进行忽略 拷贝。</span><br><span class="line"></span><br><span class="line">hdfs dfs -get /TestDir2/a.txt ./</span><br></pre></td></tr></table></figure>

<p><code>mv</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -mv URI &lt;dst&gt;</span><br><span class="line">作用 ： 将hdfs上的文件从原路径移动到目标路径（移动之后文件删除），该命令不能跨文件系统</span><br><span class="line"></span><br><span class="line">hdfs dfs -mv /TestDir2/a.txt /TestDir1</span><br></pre></td></tr></table></figure>

<p><code>rm</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -rm [-r] [skipTrash] URI [URI...]</span><br><span class="line">作用 ： 删除参数指定的文件，参数可以有多个。 -r 表示删除目录 ， -skipTrash 表示删除后不放入回收站</span><br><span class="line"></span><br><span class="line">hdfs dfs -rm /TestDir1/a.txt</span><br><span class="line">hdfs dfs -rm -r /TestDir1</span><br></pre></td></tr></table></figure>

<img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/3.png" class>

<p><code>cp</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -cp URI [URI ...] &lt;dest&gt;</span><br><span class="line">作用 ： 将文件拷贝到目标路径中，如果&lt;dest&gt;为目录的话，可以将多个文件拷贝到该目录下</span><br><span class="line">-f : 选项将覆盖目标，如果他已经存在。</span><br><span class="line">-p : 选项将保留文件属性(时间戳，所有权，许可，ACL，XAttr)</span><br><span class="line"></span><br><span class="line">hdfs dfs -cp /TestDir1/a.txt /TestDir2/b.txt</span><br></pre></td></tr></table></figure>

<p><code>cat</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat URI [uri...]</span><br><span class="line">作用 ： 将参数所指示的文件内容输出到控制台</span><br><span class="line"></span><br><span class="line">hdfs dfs -cat /TestDir1/a.txt</span><br></pre></td></tr></table></figure>

<p><code>chmod</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -chmod [-R] URI[URI...]</span><br><span class="line">作用 ： 改变文件权限。如果使用 -R 选项，则对整个目录有效递归执行。使用这一命令的用户必须是文件的所属用户，或者超级用户。</span><br><span class="line"></span><br><span class="line">hdfs dfs -chmod -R 777 /TestDir1</span><br></pre></td></tr></table></figure>

<p><code>chown</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -chmod [-R] URI[URI...]</span><br><span class="line">作用 ： 改变文件的所属用户和用户组。如果使用 -R 选项，则对整个目录有效递归执行。使用这一命令必须是文件的所属用户或者超级管理员。</span><br><span class="line"></span><br><span class="line">hdfs dfs -chown hadoop:hadoop /TestDir2/test</span><br></pre></td></tr></table></figure>

<p><code>appendToFile</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">格式 ： hdfs dfs -appendToFile &lt;localsrc&gt; ... &lt;dest&gt;</span><br><span class="line">作用 ： 追加一个或者多个文件到hdfs指定文件中。也可以从命令行读取输入</span><br><span class="line"></span><br><span class="line">hdfs dfs -appendToFile a.xml b.xml /TestDir2/big.xml</span><br><span class="line">将本地的a b文件合并一起，存为TestDir2下的 big.xml</span><br></pre></td></tr></table></figure>

<h1 id="HDFS的高级使用命令"><a href="#HDFS的高级使用命令" class="headerlink" title="HDFS的高级使用命令"></a>HDFS的高级使用命令</h1><h2 id="HDFS文件限额配置"><a href="#HDFS文件限额配置" class="headerlink" title="HDFS文件限额配置"></a>HDFS文件限额配置</h2><p>在多人共用HDFS的 环境下，配置设置非常重要。特别是在Hadoop处理大量资料的环境，如果没有配额管理，很容易把所有空间用完造成别人无法存取。HDFS的配额设定是针对目录而不是账号，可以让每个账号仅操作某一个目录，然后对目录设置配置。</p>
<p>HDFS文件的限额配置允许我们以文件个数，或者文件大小来限制我们在某个目录上传的 文件数量或者文件内容总量，以便达到我们类似网盘等限制每个用户允许上传的最大的文件的量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /user/root/dir</span><br><span class="line"></span><br><span class="line">hdfs dfs -count -q -h dir # 查看某个目录是否具有限额配置</span><br><span class="line">其中路径可以用绝对路径/user/root/dir，相对路径则直接写dir，因为HDFS默认即在user/root/目录下</span><br></pre></td></tr></table></figure>

<h3 id="数量限额"><a href="#数量限额" class="headerlink" title="数量限额"></a>数量限额</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -setQuota 2 dir # 设置该文件下最多只能上传两个文件</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：设置为2，但只能上传 1 个文件，设置为 n，上传 n - 1</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -clrQuota dir # 清除文件数量限额</span><br></pre></td></tr></table></figure>

<h3 id="空间大小限额"><a href="#空间大小限额" class="headerlink" title="空间大小限额"></a>空间大小限额</h3><p>在设置空间配额时，设置的 空间至少是Block_size * 3（128 * 3 = 384M）大小</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -setSpaceQuota 4k /user/root/dir # 限制空间大小4KB，报错，至少384M</span><br><span class="line"></span><br><span class="line">hdfs dfsadmin -clrSpaceQuota dir # 清除空间限额配置</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生成任意大小的文件命令：</span></span><br><span class="line">dd if=/dev/zero of=1.txt bs=129M count=1 # bs * count 便是想要文件的大小</span><br></pre></td></tr></table></figure>

<blockquote>
<p>分析：129M需要被分为两个Block（128M 和 1M），空间限额至少为 2 * 3 * Block_size = 768M。</p>
</blockquote>
<h2 id="HDFS的安全模式"><a href="#HDFS的安全模式" class="headerlink" title="HDFS的安全模式"></a>HDFS的安全模式</h2><p>安全模式是Hadoop的一种保护机制，用于保证集群中的数据块的安全性。当集群启动时，会首先进入安全模式。当系统出于安全模式时会检查数据块的完整性。</p>
<p>假设我们设置的副本数（即参数dfs.replication）是 3，那么在DataNode上就应该有 3 个副本，若只存在 2 个副本，那么比例就是 2 / 3 , HDFS默认的副本率为0.999，小于副本率，系统会自动的复制副本到其他DataNode。若系统超过我们设定的副本数，那么系统也会删除多余的副本。</p>
<p>在安全模式下，文件系统只接受<strong>读</strong>数据请求，而不接受删除、修改等变更请求。当整个系统达到安全标准时，HDFS会自动离开安全模式。</p>
<p><strong>安全模式操作命令</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode get		# 查看安全模式状态</span><br><span class="line">hdfs dfsadmin -safemode enter	# 进入安全模式</span><br><span class="line">hdfs dfsadmin -safemode leave	# 离开安全模式</span><br></pre></td></tr></table></figure>

<h2 id="HDFS基准测试"><a href="#HDFS基准测试" class="headerlink" title="HDFS基准测试"></a>HDFS基准测试</h2><p>实际生产环境中，Hadoop环境搭建完成后，第一件事情就是进行压力测试，测试我们的集群的读取和写入速度，测试我们的网络带宽是否满足一些测试基准</p>
<h3 id="测试写入速度"><a href="#测试写入速度" class="headerlink" title="测试写入速度"></a>测试写入速度</h3><p>向HDFS文件系统中写入数据，10文件，每个文件 10M ，文件存放的地点：／benchmarks/TestDFSIO中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/ # 测试会生成结果文件，放到该目录下</span><br><span class="line">hadoop jar /export/servers/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar TestDFSIO -write -nrFiles 10 -fileSize 10MB</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> TestDFSIO：测试DFS的IO</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> -write：测试写</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> nrFiles：写入文件数</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> fileSize：每个文件的大小</span></span><br></pre></td></tr></table></figure>

<p>命令执行完，该目录下生成测试结果的文件<code>TestDFSIO_results.log</code>，可以通过vi命令查看。</p>
<img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/4.png" class>

<p>也可通过命令查看写入速度结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -text /benchmarks/TestDFSIO/io_write/part-00000</span><br></pre></td></tr></table></figure>

<h3 id="测试读取速度"><a href="#测试读取速度" class="headerlink" title="测试读取速度"></a>测试读取速度</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /export/servers/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar TestDFSIO -read -nrFiles 10 -fileSize 10MB</span><br></pre></td></tr></table></figure>

<p>只需把 write 改为 read即可，其他文件查看等与上步一致。</p>
<h3 id="清除测试数据"><a href="#清除测试数据" class="headerlink" title="清除测试数据"></a>清除测试数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /export/servers/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar TestDFSIO clean</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：清除的是测试文件，但benchmarks还在，里面的数据清空；同样，TestDFSIO_results.log 也在。</p>
</blockquote>
<h1 id="HDFS的写入和读取过程"><a href="#HDFS的写入和读取过程" class="headerlink" title="HDFS的写入和读取过程"></a>HDFS的写入和读取过程</h1><h2 id="写入过程"><a href="#写入过程" class="headerlink" title="写入过程"></a>写入过程</h2><img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/5.png" class>

<h2 id="读取过程"><a href="#读取过程" class="headerlink" title="读取过程"></a>读取过程</h2><img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/6.png" class>

<h1 id="HDFS的元数据辅助管理"><a href="#HDFS的元数据辅助管理" class="headerlink" title="HDFS的元数据辅助管理"></a>HDFS的元数据辅助管理</h1><p>当Hadoop的集群中，NameNode的所有元数据信息都保存在了FsImage 与 Edits 文件当中。元数据信息的 保存目录配置在了hdfs-site.xml当中。</p>
<h2 id="FsImage-和-Edits-详解"><a href="#FsImage-和-Edits-详解" class="headerlink" title="FsImage 和 Edits 详解"></a>FsImage 和 Edits 详解</h2><h3 id="edits"><a href="#edits" class="headerlink" title="edits"></a>edits</h3><ul>
<li>edits 存放了客户端最近一段时间的操作日志</li>
<li>客户端对HDFS进行写文件时会首先被记录在edits文件中</li>
<li>edits修改时元数据也会更新</li>
</ul>
<h3 id="fsimage"><a href="#fsimage" class="headerlink" title="fsimage"></a>fsimage</h3><ul>
<li>NameNode中关于元数据的镜像，一般称为检查点，fsimage存放了一份比较完整的元数据信息</li>
<li>因为fsimage是NameNode的完整镜像，如果每次都加载进就非常损耗内存和CPU，所以一般开始时对NameNode的操作都放在edits中</li>
<li>随着edits内容增大，就需要在一定时间点和fsimage合并</li>
</ul>
<h2 id="fsimage中的文件信息查看"><a href="#fsimage中的文件信息查看" class="headerlink" title="fsimage中的文件信息查看"></a>fsimage中的文件信息查看</h2><p>使用命令 <code>hdfs oiv</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/hadoop-2.7.7/hadoopDatas/namenodeDatas/current</span><br><span class="line">hdfs oiv -i fsimage_0000000000000000165 -p XML -o Test.xml</span><br><span class="line">vi Test.xml</span><br></pre></td></tr></table></figure>

<h2 id="edits文件信息查看"><a href="#edits文件信息查看" class="headerlink" title="edits文件信息查看"></a>edits文件信息查看</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/hadoop-2.7.7/hadoopDatas/nn/edits/current/</span><br><span class="line">hdfs oev -i edits_0000000000000000166-0000000000000000234 -p XML -o myEdits.xml</span><br><span class="line"> vi myEdits.xml</span><br></pre></td></tr></table></figure>

<h2 id="SecondaryNameNode如何辅助管理fsimage和-edits文件？"><a href="#SecondaryNameNode如何辅助管理fsimage和-edits文件？" class="headerlink" title="SecondaryNameNode如何辅助管理fsimage和 edits文件？"></a>SecondaryNameNode如何辅助管理fsimage和 edits文件？</h2><p>只有在NameNode重启时，edit logs才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edit logs文件会变得很大。在这种情况下就会出现下面一些问题：</p>
<ol>
<li>edit logs文件会变的很大，怎么去管理这个文件是一个挑战。</li>
<li>NameNode的重启会花费很长时间，因为有很多改动[笔者注:在edit logs中]要合并到fsimage文件上。</li>
<li>如果NameNode挂掉了，那我们就丢失了很多改动因为此时的fsimage文件非常旧。[笔者注: 笔者认为在这个情况下丢失的改动不会很多, 因为丢失的改动应该是还在内存中但是没有写到edit logs的这部分。]</li>
</ol>
<p>现在我们明白了NameNode的功能和所面临的挑战 - 保持文件系统最新的元数据。那么，这些跟Secondary NameNode又有什么关系呢？</p>
<p>SecondaryNameNode就是来帮助解决上述问题的。SecondaryNameNode定期合并fsimage 和 edits，把 edits 控制在一个范围内。</p>
<img src="/2020/08/09/%E5%A4%A7%E6%95%B0%E6%8D%AE-03/7.png" class>

<p>上面的图片展示了Secondary NameNode是<strong>怎么工作</strong>的。</p>
<ol>
<li>首先，它定时到NameNode去获取edit logs，并更新到fsimage上。[笔者注：Secondary NameNode自己的fsimage]</li>
<li>一旦它有了新的fsimage文件，它将其拷贝回NameNode中。</li>
<li>NameNode在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。</li>
</ol>
<p>Secondary NameNode的整个目的是在HDFS中提供一个检查点。它只是NameNode的一个助手节点。这也是它在社区内被认为是检查点节点的原因。</p>
<p>现在，我们明白了Secondary NameNode所做的不过是在文件系统中设置一个检查点来帮助NameNode更好的工作。它不是要取代掉NameNode也不是NameNode的备份。所以从现在起，让我们养成一个习惯，称呼它为<strong>检查点节点</strong>吧。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>~感谢你请我吃糖果~</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.JPG" alt="大雪初晴丶 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>


<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束，感谢您的阅读，欢迎评论留言！-------------</div>
    
</div>
  
</div>

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE-02/" rel="prev" title="大数据_02(Hadoop概述与安装)">
      <i class="fa fa-chevron-left"></i> 大数据_02(Hadoop概述与安装)
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/10/%E5%A4%A7%E6%95%B0%E6%8D%AE-04/" rel="next" title="大数据_04(HDFS_API操作)">
      大数据_04(HDFS_API操作) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS概述"><span class="nav-number">1.</span> <span class="nav-text">HDFS概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍"><span class="nav-number">1.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS设计原则"><span class="nav-number">1.2.</span> <span class="nav-text">HDFS设计原则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#设计目标"><span class="nav-number">1.2.1.</span> <span class="nav-text">设计目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS不适合的应用类型"><span class="nav-number">1.2.2.</span> <span class="nav-text">HDFS不适合的应用类型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的架构"><span class="nav-number">2.</span> <span class="nav-text">HDFS的架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、Client：就是客户端"><span class="nav-number">2.1.</span> <span class="nav-text">1、Client：就是客户端</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、NameNode：就是Master，是一个主管、管理者"><span class="nav-number">2.2.</span> <span class="nav-text">2、NameNode：就是Master，是一个主管、管理者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、DataNode-：就是Slave。"><span class="nav-number">2.3.</span> <span class="nav-text">3、DataNode ：就是Slave。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、Secondary-NameNode"><span class="nav-number">2.4.</span> <span class="nav-text">4、Secondary NameNode</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的副本机制和机架感知"><span class="nav-number">3.</span> <span class="nav-text">HDFS的副本机制和机架感知</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS文件副本机制"><span class="nav-number">3.1.</span> <span class="nav-text">HDFS文件副本机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机架感知"><span class="nav-number">3.2.</span> <span class="nav-text">机架感知</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的命令行使用"><span class="nav-number">4.</span> <span class="nav-text">HDFS的命令行使用</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的高级使用命令"><span class="nav-number">5.</span> <span class="nav-text">HDFS的高级使用命令</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS文件限额配置"><span class="nav-number">5.1.</span> <span class="nav-text">HDFS文件限额配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数量限额"><span class="nav-number">5.1.1.</span> <span class="nav-text">数量限额</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#空间大小限额"><span class="nav-number">5.1.2.</span> <span class="nav-text">空间大小限额</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS的安全模式"><span class="nav-number">5.2.</span> <span class="nav-text">HDFS的安全模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS基准测试"><span class="nav-number">5.3.</span> <span class="nav-text">HDFS基准测试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#测试写入速度"><span class="nav-number">5.3.1.</span> <span class="nav-text">测试写入速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试读取速度"><span class="nav-number">5.3.2.</span> <span class="nav-text">测试读取速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#清除测试数据"><span class="nav-number">5.3.3.</span> <span class="nav-text">清除测试数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的写入和读取过程"><span class="nav-number">6.</span> <span class="nav-text">HDFS的写入和读取过程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#写入过程"><span class="nav-number">6.1.</span> <span class="nav-text">写入过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#读取过程"><span class="nav-number">6.2.</span> <span class="nav-text">读取过程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS的元数据辅助管理"><span class="nav-number">7.</span> <span class="nav-text">HDFS的元数据辅助管理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#FsImage-和-Edits-详解"><span class="nav-number">7.1.</span> <span class="nav-text">FsImage 和 Edits 详解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#edits"><span class="nav-number">7.1.1.</span> <span class="nav-text">edits</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fsimage"><span class="nav-number">7.1.2.</span> <span class="nav-text">fsimage</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fsimage中的文件信息查看"><span class="nav-number">7.2.</span> <span class="nav-text">fsimage中的文件信息查看</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#edits文件信息查看"><span class="nav-number">7.3.</span> <span class="nav-text">edits文件信息查看</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SecondaryNameNode如何辅助管理fsimage和-edits文件？"><span class="nav-number">7.4.</span> <span class="nav-text">SecondaryNameNode如何辅助管理fsimage和 edits文件？</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="大雪初晴丶"
      src="/images/touxiang01.jpg">
  <p class="site-author-name" itemprop="name">大雪初晴丶</p>
  <div class="site-description" itemprop="description">一个热爱编程的大二小白</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">67</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/iceWind-R" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;iceWind-R" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thorine612@gmail.com" title="E-Mail → mailto:thorine612@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.cnblogs.com/dongao/" title="https:&#x2F;&#x2F;www.cnblogs.com&#x2F;dongao&#x2F;" rel="noopener" target="_blank">博客园</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">大雪初晴丶</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">102k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:40</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div> -->
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e59d7f2168413b5" async="async"></script>
  </div>


<!-- 网站运行时间 -->
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("2/28/2020 8:00:00");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = " Runing "+dnum+" D "; 
        document.getElementById("times").innerHTML = hnum + " H " + mnum + " M " + snum + " S"; 
    } 
setInterval("createtime()",250);
</script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,255,0' opacity='0.8' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'k9OjfFxvrej9ESLrFSCkSv0C-gzGzoHsz',
      appKey     : '8MwswXHf6uKqdfpB6jYw1s5p',
      placeholder: "Just go go",
      avatar     : 'monsterid',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>